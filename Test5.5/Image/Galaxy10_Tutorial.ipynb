{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\AppStudy\\miniconda\\envs\\tf2.15\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From d:\\AppStudy\\miniconda\\envs\\tf2.15\\lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\_utils.py:48: The name tf.logging.TaskLevelStatusMessage is deprecated. Please use tf.compat.v1.logging.TaskLevelStatusMessage instead.\n",
      "\n",
      "WARNING:tensorflow:From d:\\AppStudy\\miniconda\\envs\\tf2.15\\lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\_utils.py:48: The name tf.control_flow_v2_enabled is deprecated. Please use tf.compat.v1.control_flow_v2_enabled instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import everything we need first\n",
    "import h5py\n",
    "from keras import utils\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pylab as plt\n",
    "\n",
    "from astroNN.models import Galaxy10CNN\n",
    "from astroNN.datasets import galaxy10\n",
    "from astroNN.datasets.galaxy10 import galaxy10cls_lookup, galaxy10_confusion\n",
    "\n",
    "# To get the images and labels from file\n",
    "with h5py.File('data/Galaxy10.h5', 'r') as F:\n",
    "    images = np.array(F['images'])\n",
    "    labels = np.array(F['ans'])\n",
    "# To convert to desirable type\n",
    "labels = labels.astype(np.float32)\n",
    "images = images.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\78144\\AppData\\Local\\Temp\\ipykernel_27852\\4017225513.py:13: UserWarning: Call to function train() is deprecated and will be removed in future. Use fit() instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Data: 17646, Number of Validation Data: 1960\n",
      "====Message from Normalizer====\n",
      "You selected mode: 255\n",
      "Featurewise Center: {'input': False}\n",
      "Datawise Center: {'input': False} \n",
      "Featurewise std Center: {'input': False}\n",
      "Datawise std Center: {'input': False} \n",
      "====Message ends====\n",
      "====Message from Normalizer====\n",
      "You selected mode: 0\n",
      "Featurewise Center: {'output': False}\n",
      "Datawise Center: {'output': False} \n",
      "Featurewise std Center: {'output': False}\n",
      "Datawise std Center: {'output': False} \n",
      "====Message ends====\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "compile() got an unexpected keyword argument 'sample_weight_mode'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 13\u001b[0m\n\u001b[0;32m      9\u001b[0m galaxy10net\u001b[38;5;241m.\u001b[39mmax_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# To train the nerual net\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# astroNN will normalize the data by default\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[43mgalaxy10net\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# print model summary before training\u001b[39;00m\n\u001b[0;32m     16\u001b[0m galaxy10net\u001b[38;5;241m.\u001b[39mkeras_model\u001b[38;5;241m.\u001b[39msummary()\n",
      "File \u001b[1;32md:\\AppStudy\\miniconda\\envs\\tf2.15\\lib\\site-packages\\astroNN\\shared\\warnings.py:55\u001b[0m, in \u001b[0;36mdeprecated_copy_signature.<locals>.deco.<locals>.tgt\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     49\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCall to function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() is deprecated and will be removed in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfuture. Use \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msignature_source\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     52\u001b[0m     stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m     53\u001b[0m )\n\u001b[0;32m     54\u001b[0m inspect\u001b[38;5;241m.\u001b[39msignature(signature_source)\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m target(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\AppStudy\\miniconda\\envs\\tf2.15\\lib\\site-packages\\astroNN\\models\\base_cnn.py:702\u001b[0m, in \u001b[0;36mCNNBase.train\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m \u001b[38;5;129m@deprecated_copy_signature\u001b[39m(fit)\n\u001b[0;32m    701\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 702\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\AppStudy\\miniconda\\envs\\tf2.15\\lib\\site-packages\\astroNN\\models\\base_cnn.py:394\u001b[0m, in \u001b[0;36mCNNBase.fit\u001b[1;34m(self, input_data, labels, sample_weight)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;124;03mTrain a Convolutional neural network\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;124;03m:History: 2017-Dec-06 - Written - Henry Leung (University of Toronto)\u001b[39;00m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    393\u001b[0m \u001b[38;5;66;03m# Call the checklist to create astroNN folder and save parameters\u001b[39;00m\n\u001b[1;32m--> 394\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpre_training_checklist_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    396\u001b[0m reduce_lr \u001b[38;5;241m=\u001b[39m ReduceLROnPlateau(\n\u001b[0;32m    397\u001b[0m     monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    398\u001b[0m     factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    403\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    404\u001b[0m )\n\u001b[0;32m    406\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(\n\u001b[0;32m    407\u001b[0m     monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    408\u001b[0m     min_delta\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mearly_stopping_min_delta,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    411\u001b[0m     mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    412\u001b[0m )\n",
      "File \u001b[1;32md:\\AppStudy\\miniconda\\envs\\tf2.15\\lib\\site-packages\\astroNN\\models\\base_cnn.py:319\u001b[0m, in \u001b[0;36mCNNBase.pre_training_checklist_child\u001b[1;34m(self, input_data, labels, sample_weight)\u001b[0m\n\u001b[0;32m    315\u001b[0m     norm_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels_normalizer\u001b[38;5;241m.\u001b[39mnormalize(labels, calc\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeras_model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    318\u001b[0m ):  \u001b[38;5;66;03m# only compile if there is no keras_model, e.g. fine-tuning does not required\u001b[39;00m\n\u001b[1;32m--> 319\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m norm_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensor_dict_sanitize(norm_data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeras_model\u001b[38;5;241m.\u001b[39minput_names)\n\u001b[0;32m    322\u001b[0m norm_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensor_dict_sanitize(\n\u001b[0;32m    323\u001b[0m     norm_labels, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeras_model\u001b[38;5;241m.\u001b[39moutput_names\n\u001b[0;32m    324\u001b[0m )\n",
      "File \u001b[1;32md:\\AppStudy\\miniconda\\envs\\tf2.15\\lib\\site-packages\\astroNN\\models\\base_cnn.py:235\u001b[0m, in \u001b[0;36mCNNBase.compile\u001b[1;34m(self, optimizer, loss, metrics, weighted_metrics, loss_weights, sample_weight_mode)\u001b[0m\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    230\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOnly \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregression\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassification\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary_classification\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m are supported\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    231\u001b[0m     )\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeras_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel()\n\u001b[1;32m--> 235\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweighted_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweighted_metrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    241\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    242\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;66;03m# inject custom training step if needed\u001b[39;00m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32md:\\AppStudy\\miniconda\\envs\\tf2.15\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32md:\\AppStudy\\miniconda\\envs\\tf2.15\\lib\\site-packages\\keras\\src\\utils\\tracking.py:26\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(fn)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m DotNotTrackScope():\n\u001b[1;32m---> 26\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mTypeError\u001b[0m: compile() got an unexpected keyword argument 'sample_weight_mode'"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training set and testing set\n",
    "train_idx, test_idx = train_test_split(np.arange(labels.shape[0]), test_size=0.1)\n",
    "train_images, train_labels, test_images, test_labels = images[train_idx], labels[train_idx], images[test_idx], labels[test_idx]\n",
    "\n",
    "# To create a neural network instance\n",
    "galaxy10net = Galaxy10CNN()\n",
    "\n",
    "# set maximium epochs the neural network can run, set 5 to get quick result\n",
    "galaxy10net.max_epochs = 5\n",
    "\n",
    "# To train the nerual net\n",
    "# astroNN will normalize the data by default\n",
    "galaxy10net.train(train_images, train_labels)\n",
    "\n",
    "# print model summary before training\n",
    "galaxy10net.keras_model.summary()\n",
    "\n",
    "# After the training, you can test the neural net performance\n",
    "# Please notice predicted_labels are labels predicted from neural network. test_labels are ground truth from the dataset\n",
    "predicted_labels = galaxy10net.test(test_images)\n",
    "\n",
    "# Convert predicted_labels to class\n",
    "prediction_class = np.argmax(predicted_labels, axis=1)\n",
    "\n",
    "# Convert test_labels to class\n",
    "test_class = np.argmax(test_labels, axis=1)\n",
    "\n",
    "# Prepare a confusion matrix\n",
    "confusion_matrix = np.zeros((10,10))\n",
    "\n",
    "# create the confusion matrix\n",
    "for counter, i in enumerate(prediction_class):\n",
    "    confusion_matrix[i, test_class[counter]] += 1\n",
    "\n",
    "# Plot the confusion matrix\n",
    "galaxy10_confusion(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\78144\\AppData\\Local\\Temp\\ipykernel_2824\\3280483497.py:17: UserWarning: Call to function train() is deprecated and will be removed in future. Use fit() instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Data: 17646, Number of Validation Data: 1960\n",
      "====Message from Normalizer====\n",
      "You selected mode: 255\n",
      "Featurewise Center: {'input': False}\n",
      "Datawise Center: {'input': False} \n",
      "Featurewise std Center: {'input': False}\n",
      "Datawise std Center: {'input': False} \n",
      "====Message ends====\n",
      "====Message from Normalizer====\n",
      "You selected mode: 0\n",
      "Featurewise Center: {'output': False}\n",
      "Datawise Center: {'output': False} \n",
      "Featurewise std Center: {'output': False}\n",
      "Datawise std Center: {'output': False} \n",
      "====Message ends====\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "compile() got an unexpected keyword argument 'sample_weight_mode'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 17\u001b[0m\n\u001b[0;32m     13\u001b[0m galaxy10net\u001b[38;5;241m.\u001b[39mmax_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# To train the nerual net\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# astroNN will normalize the data by default\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[43mgalaxy10net\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# print model summary before training\u001b[39;00m\n\u001b[0;32m     20\u001b[0m galaxy10net\u001b[38;5;241m.\u001b[39mkeras_model\u001b[38;5;241m.\u001b[39msummary()\n",
      "File \u001b[1;32md:\\AppStudy\\miniconda\\envs\\tf2.15\\lib\\site-packages\\astroNN\\shared\\warnings.py:55\u001b[0m, in \u001b[0;36mdeprecated_copy_signature.<locals>.deco.<locals>.tgt\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     49\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCall to function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() is deprecated and will be removed in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfuture. Use \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msignature_source\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     52\u001b[0m     stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m     53\u001b[0m )\n\u001b[0;32m     54\u001b[0m inspect\u001b[38;5;241m.\u001b[39msignature(signature_source)\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m target(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\AppStudy\\miniconda\\envs\\tf2.15\\lib\\site-packages\\astroNN\\models\\base_cnn.py:702\u001b[0m, in \u001b[0;36mCNNBase.train\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m \u001b[38;5;129m@deprecated_copy_signature\u001b[39m(fit)\n\u001b[0;32m    701\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 702\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\AppStudy\\miniconda\\envs\\tf2.15\\lib\\site-packages\\astroNN\\models\\base_cnn.py:394\u001b[0m, in \u001b[0;36mCNNBase.fit\u001b[1;34m(self, input_data, labels, sample_weight)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;124;03mTrain a Convolutional neural network\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;124;03m:History: 2017-Dec-06 - Written - Henry Leung (University of Toronto)\u001b[39;00m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    393\u001b[0m \u001b[38;5;66;03m# Call the checklist to create astroNN folder and save parameters\u001b[39;00m\n\u001b[1;32m--> 394\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpre_training_checklist_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    396\u001b[0m reduce_lr \u001b[38;5;241m=\u001b[39m ReduceLROnPlateau(\n\u001b[0;32m    397\u001b[0m     monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    398\u001b[0m     factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    403\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    404\u001b[0m )\n\u001b[0;32m    406\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(\n\u001b[0;32m    407\u001b[0m     monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    408\u001b[0m     min_delta\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mearly_stopping_min_delta,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    411\u001b[0m     mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    412\u001b[0m )\n",
      "File \u001b[1;32md:\\AppStudy\\miniconda\\envs\\tf2.15\\lib\\site-packages\\astroNN\\models\\base_cnn.py:319\u001b[0m, in \u001b[0;36mCNNBase.pre_training_checklist_child\u001b[1;34m(self, input_data, labels, sample_weight)\u001b[0m\n\u001b[0;32m    315\u001b[0m     norm_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels_normalizer\u001b[38;5;241m.\u001b[39mnormalize(labels, calc\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeras_model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    318\u001b[0m ):  \u001b[38;5;66;03m# only compile if there is no keras_model, e.g. fine-tuning does not required\u001b[39;00m\n\u001b[1;32m--> 319\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m norm_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensor_dict_sanitize(norm_data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeras_model\u001b[38;5;241m.\u001b[39minput_names)\n\u001b[0;32m    322\u001b[0m norm_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensor_dict_sanitize(\n\u001b[0;32m    323\u001b[0m     norm_labels, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeras_model\u001b[38;5;241m.\u001b[39moutput_names\n\u001b[0;32m    324\u001b[0m )\n",
      "File \u001b[1;32md:\\AppStudy\\miniconda\\envs\\tf2.15\\lib\\site-packages\\astroNN\\models\\base_cnn.py:235\u001b[0m, in \u001b[0;36mCNNBase.compile\u001b[1;34m(self, optimizer, loss, metrics, weighted_metrics, loss_weights, sample_weight_mode)\u001b[0m\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    230\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOnly \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregression\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassification\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary_classification\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m are supported\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    231\u001b[0m     )\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeras_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel()\n\u001b[1;32m--> 235\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweighted_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweighted_metrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    241\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    242\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;66;03m# inject custom training step if needed\u001b[39;00m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32md:\\AppStudy\\miniconda\\envs\\tf2.15\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32md:\\AppStudy\\miniconda\\envs\\tf2.15\\lib\\site-packages\\keras\\src\\utils\\tracking.py:26\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(fn)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m DotNotTrackScope():\n\u001b[1;32m---> 26\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mTypeError\u001b[0m: compile() got an unexpected keyword argument 'sample_weight_mode'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Split the dataset into training set and testing set\n",
    "train_idx, test_idx = train_test_split(np.arange(labels.shape[0]), test_size=0.1)\n",
    "train_images, train_labels, test_images, test_labels = images[train_idx], labels[train_idx], images[test_idx], labels[test_idx]\n",
    "\n",
    "# To create a neural network instance\n",
    "galaxy10net = Galaxy10CNN()\n",
    "\n",
    "# set maximium epochs the neural network can run, set 5 to get quick result\n",
    "galaxy10net.max_epochs = 5\n",
    "\n",
    "# To train the nerual net\n",
    "# astroNN will normalize the data by default\n",
    "galaxy10net.train(train_images, train_labels)\n",
    "\n",
    "# print model summary before training\n",
    "galaxy10net.keras_model.summary()\n",
    "\n",
    "# After the training, you can test the neural net performance\n",
    "# Please notice predicted_labels are labels predicted from neural network. test_labels are ground truth from the dataset\n",
    "predicted_labels = galaxy10net.test(test_images)\n",
    "\n",
    "# Convert predicted_labels to class\n",
    "prediction_class = np.argmax(predicted_labels, axis=1)\n",
    "\n",
    "# Convert test_labels to class\n",
    "test_class = np.argmax(test_labels, axis=1)\n",
    "\n",
    "# Prepare a confusion matrix\n",
    "confusion_matrix = np.zeros((10,10))\n",
    "\n",
    "# create the confusion matrix\n",
    "for counter, i in enumerate(prediction_class):\n",
    "    confusion_matrix[i, test_class[counter]] += 1\n",
    "\n",
    "# Plot the confusion matrix\n",
    "galaxy10_confusion(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
